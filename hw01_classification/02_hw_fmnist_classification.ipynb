{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 7')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModel(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model_task_1 = FashionMNISTModel()\n",
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:12<02:55, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 0.2038, Train Acc: 0.9225\n",
      "Val Loss: 0.3519, Val Acc: 0.8884\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:23<02:32, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "Train Loss: 0.1936, Train Acc: 0.9266\n",
      "Val Loss: 0.3711, Val Acc: 0.8854\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:35<02:18, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "Train Loss: 0.1858, Train Acc: 0.9286\n",
      "Val Loss: 0.3915, Val Acc: 0.8868\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:46<02:05, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "Train Loss: 0.1822, Train Acc: 0.9305\n",
      "Val Loss: 0.3863, Val Acc: 0.8905\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:58<01:56, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "Train Loss: 0.1748, Train Acc: 0.9332\n",
      "Val Loss: 0.3859, Val Acc: 0.8889\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:10<01:45, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "Train Loss: 0.1719, Train Acc: 0.9346\n",
      "Val Loss: 0.3868, Val Acc: 0.8978\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:22<01:34, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "Train Loss: 0.1677, Train Acc: 0.9359\n",
      "Val Loss: 0.3916, Val Acc: 0.8949\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [01:34<01:22, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "Train Loss: 0.1614, Train Acc: 0.9374\n",
      "Val Loss: 0.3967, Val Acc: 0.8974\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:45<01:10, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "Train Loss: 0.1623, Train Acc: 0.9383\n",
      "Val Loss: 0.3996, Val Acc: 0.8901\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [01:57<00:59, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "Train Loss: 0.1524, Train Acc: 0.9408\n",
      "Val Loss: 0.4920, Val Acc: 0.8864\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [02:10<00:48, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "Train Loss: 0.1517, Train Acc: 0.9422\n",
      "Val Loss: 0.4221, Val Acc: 0.8932\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [02:22<00:36, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Train Loss: 0.1484, Train Acc: 0.9425\n",
      "Val Loss: 0.4513, Val Acc: 0.8962\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [02:34<00:24, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "Train Loss: 0.1454, Train Acc: 0.9448\n",
      "Val Loss: 0.4609, Val Acc: 0.8878\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [02:46<00:12, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "Train Loss: 0.1414, Train Acc: 0.9466\n",
      "Val Loss: 0.4669, Val Acc: 0.8952\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [02:58<00:00, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "Train Loss: 0.1386, Train Acc: 0.9463\n",
      "Val Loss: 0.4724, Val Acc: 0.8868\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_task_1.parameters(), lr=1e-3)\n",
    "\n",
    "# Функция для обучения модели\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Функция для валидации модели\n",
    "def validate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Обучение модели\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_epoch(model_task_1, train_data_loader, loss_fn, optimizer)\n",
    "    val_loss, val_acc = validate(model_task_1, test_data_loader, loss_fn)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.94978\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8868\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_fmnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
